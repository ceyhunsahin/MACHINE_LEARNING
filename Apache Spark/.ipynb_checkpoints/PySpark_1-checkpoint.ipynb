{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2e05f0d",
   "metadata": {},
   "source": [
    "# Usually, there are two popular ways to create the RDDs: loading an external dataset, or distributing a set of collection of objects. The following examples show some simplest ways to create RDDs by using parallelize() fucntion which takes an already existing collection in your program and pass the same to the Spark Context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ab6002",
   "metadata": {},
   "source": [
    "### By using parallelize( ) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e7051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"PYthon Spark Create RDD Ex\").config('spark.some.config.option', 'some-value')\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652fcc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-----+\n",
      "|  a|  b|  c|    d|\n",
      "+---+---+---+-----+\n",
      "|  1|  2|  3|a b c|\n",
      "|  4|  5|  6|d e f|\n",
      "|  7|  8|  9|g h i|\n",
      "+---+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sparkContext.parallelize([(1,2,3,'a b c'), (4,5,6,'d e f'), (7, 8, 9, 'g h i')]).toDF(['a', 'b', 'c', 'd'])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d0f2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (3, 4), (5, 6), (7, 8), (9, 10)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myData = spark.sparkContext.parallelize([(1,2), (3,4), (5,6), (7,8), (9,10)])\n",
    "\n",
    "myData.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c87f723",
   "metadata": {},
   "source": [
    "### By using createDataFrame( ) function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf03dd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------+------------+\n",
      "| Id| Name|Sallary|DepartmentId|\n",
      "+---+-----+-------+------------+\n",
      "|  1|  Joe|  70000|           1|\n",
      "|  2|Henry|  80000|           2|\n",
      "|  3|  Sam|  60000|           2|\n",
      "|  4|  Max|  90000|           1|\n",
      "+---+-----+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Employee = spark.createDataFrame([\n",
    "                        ('1', 'Joe',   '70000', '1'),\n",
    "                        ('2', 'Henry', '80000', '2'),\n",
    "                        ('3', 'Sam',   '60000', '2'),\n",
    "                        ('4', 'Max',   '90000', '1')],\n",
    "                        ['Id', 'Name', 'Sallary','DepartmentId']\n",
    ")\n",
    "\n",
    "Employee.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d936c6c9",
   "metadata": {},
   "source": [
    "### Read dataset from .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a502374",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv').options(header = 'true', inferschema = 'true').\\\n",
    "load('Customer-Churn.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d298816d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "|7590-VHVEG|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|         29.85|       29.85|   No|\n",
      "|5575-GNVDE|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|        Mailed check|         56.95|      1889.5|   No|\n",
      "|3668-QPYBK|  Male|            0|     No|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|        Mailed check|         53.85|      108.15|  Yes|\n",
      "|7795-CFOCW|  Male|            0|     No|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|Bank transfer (au...|          42.3|     1840.75|   No|\n",
      "|9237-HQITU|Female|            0|     No|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|          70.7|      151.65|  Yes|\n",
      "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- SeniorCitizen: integer (nullable = true)\n",
      " |-- Partner: string (nullable = true)\n",
      " |-- Dependents: string (nullable = true)\n",
      " |-- tenure: integer (nullable = true)\n",
      " |-- PhoneService: string (nullable = true)\n",
      " |-- MultipleLines: string (nullable = true)\n",
      " |-- InternetService: string (nullable = true)\n",
      " |-- OnlineSecurity: string (nullable = true)\n",
      " |-- OnlineBackup: string (nullable = true)\n",
      " |-- DeviceProtection: string (nullable = true)\n",
      " |-- TechSupport: string (nullable = true)\n",
      " |-- StreamingTV: string (nullable = true)\n",
      " |-- StreamingMovies: string (nullable = true)\n",
      " |-- Contract: string (nullable = true)\n",
      " |-- PaperlessBilling: string (nullable = true)\n",
      " |-- PaymentMethod: string (nullable = true)\n",
      " |-- MonthlyCharges: double (nullable = true)\n",
      " |-- TotalCharges: string (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa05803",
   "metadata": {},
   "source": [
    "### Read dataset from DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2849c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "# spark = SparkSession \\\n",
    "#             .builder \\\n",
    "#             .appName(\"Python Spark create RDD example\") \\\n",
    "#             .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "#             .getOrCreate()\n",
    "# ## User information\n",
    "# user = 'your_username'\n",
    "# pw   = 'your_password'\n",
    "# ## Database information\n",
    "# table_name = 'table_name'\n",
    "# url = 'jdbc:postgresql://##.###.###.##:5432/dataset?user='+user+'&password='+pw\n",
    "# properties ={'driver': 'org.postgresql.Driver', 'password': pw,'user\n",
    "# ˓→': user}\n",
    "# df = spark.read.jdbc(url=url, table=table_name,properties=properties)\n",
    "# df.show(5)\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2659d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  0  1  1\n",
       "1  1  0  0\n",
       "2  0  1  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'A': [0, 1, 0],\n",
    "     'B': [1, 0, 1],\n",
    "     'C': [1, 0, 0]}\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef104c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaa [[0 1 0]\n",
      " [1 0 1]\n",
      " [1 0 0]]\n",
      "bbbb [[0 1 1]\n",
      " [1 0 0]\n",
      " [0 1 0]]\n",
      "cccc [[0, 1, 1], [1, 0, 0], [0, 1, 0]]\n",
      "+---+---+---+\n",
      "|  A|  B|  C|\n",
      "+---+---+---+\n",
      "|  0|  1|  1|\n",
      "|  1|  0|  0|\n",
      "|  0|  1|  0|\n",
      "+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a  = np.array(list(d.values()))\n",
    "b = np.array(list(d.values())).T\n",
    "c = np.array(list(d.values())).T.tolist()\n",
    "print('aaaa',a)\n",
    "print('bbbb',b)\n",
    "print('cccc',c)\n",
    "spark.createDataFrame(np.array(list(d.values())).T.tolist(), list(d.keys())).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c99d879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0     TV  Radio  Newspaper  Sales\n",
      "0             1  230.1   37.8       69.2   22.1\n",
      "1             2   44.5   39.3       45.1   10.4\n",
      "2             3   17.2   45.9       69.3    9.3\n",
      "3             4  151.5   41.3       58.5   18.5\n",
      "4             5  180.8   10.8       58.4   12.9\n",
      "..          ...    ...    ...        ...    ...\n",
      "195         196   38.2    3.7       13.8    7.6\n",
      "196         197   94.2    4.9        8.1    9.7\n",
      "197         198  177.0    9.3        6.4   12.8\n",
      "198         199  283.6   42.0       66.2   25.5\n",
      "199         200  232.1    8.6        8.7   13.4\n",
      "\n",
      "[200 rows x 5 columns]\n",
      "+---+-----+-----+---------+-----+\n",
      "|_c0|   TV|Radio|Newspaper|Sales|\n",
      "+---+-----+-----+---------+-----+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3|\n",
      "|  4|151.5| 41.3|     58.5| 18.5|\n",
      "|  5|180.8| 10.8|     58.4| 12.9|\n",
      "|  6|  8.7| 48.9|     75.0|  7.2|\n",
      "|  7| 57.5| 32.8|     23.5| 11.8|\n",
      "|  8|120.2| 19.6|     11.6| 13.2|\n",
      "|  9|  8.6|  2.1|      1.0|  4.8|\n",
      "| 10|199.8|  2.6|     21.2| 10.6|\n",
      "| 11| 66.1|  5.8|     24.2|  8.6|\n",
      "| 12|214.7| 24.0|      4.0| 17.4|\n",
      "| 13| 23.8| 35.1|     65.9|  9.2|\n",
      "| 14| 97.5|  7.6|      7.2|  9.7|\n",
      "| 15|204.1| 32.9|     46.0| 19.0|\n",
      "| 16|195.4| 47.7|     52.9| 22.4|\n",
      "| 17| 67.8| 36.6|    114.0| 12.5|\n",
      "| 18|281.4| 39.6|     55.8| 24.4|\n",
      "| 19| 69.2| 20.5|     18.3| 11.3|\n",
      "| 20|147.3| 23.9|     19.1| 14.6|\n",
      "+---+-----+-----+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pd.DataFrame dp: DataFrame pandas\n",
    "dp = pd.read_csv('Advertising.csv') #rdd.DataFrame. dp: DataFrame spark\n",
    "ds = spark.read.csv('Advertising.csv',\n",
    "# # #\n",
    "sep=',',\n",
    "encoding='UTF-8',\n",
    "comment=None,\n",
    "header=True,\n",
    "inferSchema=True)\n",
    "print(dp)\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2152fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp = pd.read_json(\"http://api.luftdaten.info/static/v1/data.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a761ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = spark.read.json('data.json')\n",
    "#ds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd2815fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp[['id','timestamp']].head(4) # \n",
    "#ds[['id','timestamp']].show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecf0d085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', 'TV', 'Radio', 'Newspaper', 'Sales']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a16e4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+\n",
      "|     A|  B|   C|\n",
      "+------+---+----+\n",
      "|  male|  1|null|\n",
      "|female|  2|   3|\n",
      "|  male|  3|   4|\n",
      "+------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_list = [['male', 1, None], ['female', 2, 3],['male', 3, 4]] \n",
    "dp = pd.DataFrame(my_list,columns=['A', 'B', 'C'])\n",
    "ds = spark.createDataFrame(my_list, ['A', 'B', 'C'])\n",
    "#\n",
    "dp.head()\n",
    "ds.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10cddc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---+\n",
      "|     A|  B|  C|\n",
      "+------+---+---+\n",
      "|  male|  1|-99|\n",
      "|female|  2|  3|\n",
      "|  male|  3|  4|\n",
      "+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.fillna(-99).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e346f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B    C\n",
      "0  1  1  NaN\n",
      "1  0  2  3.0\n",
      "2  1  3  4.0\n",
      "+---+---+----+\n",
      "|  A|  B|   C|\n",
      "+---+---+----+\n",
      "|  1|  1|null|\n",
      "|  0|  2|   3|\n",
      "|  1|  3|   4|\n",
      "+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# caution: you need to chose specific col\n",
    "dp.A.replace(['male', 'female'],[1, 0], inplace=True) \n",
    "print(dp)\n",
    "#caution: Mixed type replacements are not supported \n",
    "ds.na.replace(['male','female'],['1','0']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29b03747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  Radio     C     D\n",
       "0           1  230.1   37.8  69.2  22.1\n",
       "1           2   44.5   39.3  45.1  10.4\n",
       "2           3   17.2   45.9  69.3   9.3\n",
       "3           4  151.5   41.3  58.5  18.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = pd.read_csv('Advertising.csv') #rdd.DataFrame. dp: DataFrame pandas\n",
    "ds = spark.read.csv('Advertising.csv',sep=',',\n",
    "encoding='UTF-8',\n",
    "comment=None,\n",
    "header=True,\n",
    "inferSchema=True)\n",
    "mapping = {'Newspaper':'C','Sales':'D'}\n",
    "dp.rename(columns=mapping).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c94a42c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+-----+\n",
      "|_c0|   TV|Radio|Newspaper|Sales|\n",
      "+---+-----+-----+---------+-----+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3|\n",
      "|  4|151.5| 41.3|     58.5| 18.5|\n",
      "|  5|180.8| 10.8|     58.4| 12.9|\n",
      "|  6|  8.7| 48.9|     75.0|  7.2|\n",
      "|  7| 57.5| 32.8|     23.5| 11.8|\n",
      "|  8|120.2| 19.6|     11.6| 13.2|\n",
      "|  9|  8.6|  2.1|      1.0|  4.8|\n",
      "| 10|199.8|  2.6|     21.2| 10.6|\n",
      "| 11| 66.1|  5.8|     24.2|  8.6|\n",
      "| 12|214.7| 24.0|      4.0| 17.4|\n",
      "| 13| 23.8| 35.1|     65.9|  9.2|\n",
      "| 14| 97.5|  7.6|      7.2|  9.7|\n",
      "| 15|204.1| 32.9|     46.0| 19.0|\n",
      "| 16|195.4| 47.7|     52.9| 22.4|\n",
      "| 17| 67.8| 36.6|    114.0| 12.5|\n",
      "| 18|281.4| 39.6|     55.8| 24.4|\n",
      "| 19| 69.2| 20.5|     18.3| 11.3|\n",
      "| 20|147.3| 23.9|     19.1| 14.6|\n",
      "+---+-----+-----+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Radio\n",
      "['_c0', 'TV', 'Radio', 'C', 'D']\n",
      "['_c0', 'TV', 'Radio', 'Newspaper', 'Sales']\n",
      "+---+-----+-----+----+----+\n",
      "|_c0|   TV|Radio|   C|   D|\n",
      "+---+-----+-----+----+----+\n",
      "|  1|230.1| 37.8|69.2|22.1|\n",
      "|  2| 44.5| 39.3|45.1|10.4|\n",
      "|  3| 17.2| 45.9|69.3| 9.3|\n",
      "|  4|151.5| 41.3|58.5|18.5|\n",
      "+---+-----+-----+----+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.show()\n",
    "new_names = [mapping.get(col,col) for col in ds.columns] \n",
    "print(mapping.get(1,'Radio'))\n",
    "print(new_names)\n",
    "print(ds.columns)\n",
    "ds.toDF(*new_names).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88bf015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+-----+-----+\n",
      "|_c0|   TV|Radio|Paper|Sales|\n",
      "+---+-----+-----+-----+-----+\n",
      "|  1|230.1| 37.8| 69.2| 22.1|\n",
      "|  2| 44.5| 39.3| 45.1| 10.4|\n",
      "|  3| 17.2| 45.9| 69.3|  9.3|\n",
      "|  4|151.5| 41.3| 58.5| 18.5|\n",
      "+---+-----+-----+-----+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.withColumnRenamed('Newspaper','Paper').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15e76b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+--------------+\n",
      "|_c0|   TV|Radio|Newspaper|derniere_sales|\n",
      "+---+-----+-----+---------+--------------+\n",
      "|  1|230.1| 37.8|     69.2|          22.1|\n",
      "|  2| 44.5| 39.3|     45.1|          10.4|\n",
      "|  3| 17.2| 45.9|     69.3|           9.3|\n",
      "|  4|151.5| 41.3|     58.5|          18.5|\n",
      "+---+-----+-----+---------+--------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.withColumnRenamed('Sales','derniere_sales').show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a161ad8",
   "metadata": {},
   "source": [
    "## Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21a29696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  Radio\n",
       "0           1  230.1   37.8\n",
       "1           2   44.5   39.3\n",
       "2           3   17.2   45.9\n",
       "3           4  151.5   41.3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_name = ['Newspaper','Sales']\n",
    "dp.drop(drop_name,axis=1).head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ff5dc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+\n",
      "|_c0|   TV|Radio|\n",
      "+---+-----+-----+\n",
      "|  1|230.1| 37.8|\n",
      "|  2| 44.5| 39.3|\n",
      "|  3| 17.2| 45.9|\n",
      "|  4|151.5| 41.3|\n",
      "+---+-----+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.drop(*drop_name).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7bb7745b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>120.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>214.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>147.3</td>\n",
       "      <td>23.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>262.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>19.5</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0     TV  Radio  Newspaper  Sales\n",
       "7            8  120.2   19.6       11.6   13.2\n",
       "11          12  214.7   24.0        4.0   17.4\n",
       "19          20  147.3   23.9       19.1   14.6\n",
       "25          26  262.9    3.5       19.5   12.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp[(dp.Newspaper<20)&(dp.TV>100)].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e663d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+-----+\n",
      "|_c0|   TV|Radio|Newspaper|Sales|\n",
      "+---+-----+-----+---------+-----+\n",
      "|  8|120.2| 19.6|     11.6| 13.2|\n",
      "| 12|214.7| 24.0|      4.0| 17.4|\n",
      "| 20|147.3| 23.9|     19.1| 14.6|\n",
      "| 26|262.9|  3.5|     19.5| 12.0|\n",
      "+---+-----+-----+---------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds[(ds.Newspaper<20)&(ds.TV>100)].show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e96ae4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "      <th>tv_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.007824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.001513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.000585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "      <td>0.005152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.006148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     TV  Radio  Newspaper  Sales   tv_norm\n",
       "0           1  230.1   37.8       69.2   22.1  0.007824\n",
       "1           2   44.5   39.3       45.1   10.4  0.001513\n",
       "2           3   17.2   45.9       69.3    9.3  0.000585\n",
       "3           4  151.5   41.3       58.5   18.5  0.005152\n",
       "4           5  180.8   10.8       58.4   12.9  0.006148"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp['tv_norm'] = dp.TV/sum(dp.TV)\n",
    "dp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ae317e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29408.499999999996"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "ds.groupBy().agg(F.sum(\"TV\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea03726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec16b6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+-----+--------------------+\n",
      "|_c0|   TV|Radio|Newspaper|Sales|             tv_norm|\n",
      "+---+-----+-----+---------+-----+--------------------+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|0.007824268493802813|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4|0.001513167961643...|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3|5.848649200061207E-4|\n",
      "|  4|151.5| 41.3|     58.5| 18.5|0.005151571824472517|\n",
      "+---+-----+-----+---------+-----+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.withColumn('tv_norm', ds.TV/ds.groupBy().agg(F.sum(\"TV\")).collect()[0][0]).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5e59822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     TV  Radio  Newspaper  Sales   tv_norm    log_tv\n",
      "0           1  230.1   37.8       69.2   22.1  0.007824  5.438514\n",
      "1           2   44.5   39.3       45.1   10.4  0.001513  3.795489\n",
      "2           3   17.2   45.9       69.3    9.3  0.000585  2.844909\n",
      "3           4  151.5   41.3       58.5   18.5  0.005152  5.020586\n",
      "+---+-----+-----+---------+-----+------------------+\n",
      "|_c0|   TV|Radio|Newspaper|Sales|            log_tv|\n",
      "+---+-----+-----+---------+-----+------------------+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|  5.43851399704132|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4|3.7954891891721947|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3|2.8449093838194073|\n",
      "|  4|151.5| 41.3|     58.5| 18.5| 5.020585624949424|\n",
      "+---+-----+-----+---------+-----+------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp['log_tv'] = np.log(dp.TV)\n",
    "print(dp.head(4))\n",
    "#\n",
    "import pyspark.sql.functions as F \n",
    "ds.withColumn('log_tv',F.log(ds.TV)).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e001435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+---------+-----+--------------------+\n",
      "|_c0|   TV|Radio|Newspaper|Sales|              ekstra|\n",
      "+---+-----+-----+---------+-----+--------------------+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|0.007824268493802813|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4|0.001513167961643...|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3|5.848649200061207E-4|\n",
      "|  4|151.5| 41.3|     58.5| 18.5|0.005151571824472517|\n",
      "|  5|180.8| 10.8|     58.4| 12.9|0.006147882414948061|\n",
      "+---+-----+-----+---------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F \n",
    "ds.withColumn('ekstra',ds.TV/ds.groupBy().agg(F.sum('TV')).collect()[0][0]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90989457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     TV  Radio  Newspaper  Sales   tv_norm    log_tv  tv+10\n",
      "0           1  230.1   37.8       69.2   22.1  0.007824  5.438514  240.1\n",
      "1           2   44.5   39.3       45.1   10.4  0.001513  3.795489   54.5\n",
      "2           3   17.2   45.9       69.3    9.3  0.000585  2.844909   27.2\n",
      "3           4  151.5   41.3       58.5   18.5  0.005152  5.020586  161.5\n",
      "+---+-----+-----+---------+-----+-----+\n",
      "|_c0|   TV|Radio|Newspaper|Sales|tv+10|\n",
      "+---+-----+-----+---------+-----+-----+\n",
      "|  1|230.1| 37.8|     69.2| 22.1|240.1|\n",
      "|  2| 44.5| 39.3|     45.1| 10.4| 54.5|\n",
      "|  3| 17.2| 45.9|     69.3|  9.3| 27.2|\n",
      "|  4|151.5| 41.3|     58.5| 18.5|161.5|\n",
      "+---+-----+-----+---------+-----+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, TV: double, Radio: double, Newspaper: double, Sales: double]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp['tv+10'] = dp.TV.apply(lambda x: x+10) \n",
    "print(dp.head(4))\n",
    "#\n",
    "ds.withColumn('tv+10', ds.TV+10).show(4)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed666eb3",
   "metadata": {},
   "source": [
    "### JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8a1e22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "    A   F   G   H\n",
      "4  A0  B4  C4  D4\n",
      "5  A1  B5  C5  D5\n",
      "6  A6  B6  C6  D6\n",
      "7  A7  B7  C7  D7\n"
     ]
    }
   ],
   "source": [
    "leftp = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                    index=[0, 1, 2, 3])\n",
    "print(leftp)\n",
    "rightp = pd.DataFrame({'A': ['A0', 'A1', 'A6', 'A7'],\n",
    "                       'F': ['B4', 'B5', 'B6', 'B7'],\n",
    "                       'G': ['C4', 'C5', 'C6', 'C7'],\n",
    "                       'H': ['D4', 'D5', 'D6', 'D7']},\n",
    "                       index=[4, 5, 6, 7])\n",
    "print(rightp)\n",
    "lefts = spark.createDataFrame(leftp)\n",
    "rights = spark.createDataFrame(rightp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91cb2b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "      <td>D1</td>\n",
       "      <td>B5</td>\n",
       "      <td>C5</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2</td>\n",
       "      <td>B2</td>\n",
       "      <td>C2</td>\n",
       "      <td>D2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3</td>\n",
       "      <td>B3</td>\n",
       "      <td>C3</td>\n",
       "      <td>D3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D    F    G    H\n",
       "0  A0  B0  C0  D0   B4   C4   D4\n",
       "1  A1  B1  C1  D1   B5   C5   D5\n",
       "2  A2  B2  C2  D2  NaN  NaN  NaN\n",
       "3  A3  B3  C3  D3  NaN  NaN  NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Left Join\n",
    "leftp.merge(rightp,on='A',how='left') # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02997a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+----+----+----+\n",
      "|  A|  B|  C|  D|   F|   G|   H|\n",
      "+---+---+---+---+----+----+----+\n",
      "| A0| B0| C0| D0|  B4|  C4|  D4|\n",
      "| A1| B1| C1| D1|  B5|  C5|  D5|\n",
      "| A2| B2| C2| D2|null|null|null|\n",
      "| A3| B3| C3| D3|null|null|null|\n",
      "+---+---+---+---+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lefts.join(rights,on='A',how='left').orderBy('A',ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8c4a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Right Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9bf13e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0</td>\n",
       "      <td>B0</td>\n",
       "      <td>C0</td>\n",
       "      <td>D0</td>\n",
       "      <td>B4</td>\n",
       "      <td>C4</td>\n",
       "      <td>D4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1</td>\n",
       "      <td>B1</td>\n",
       "      <td>C1</td>\n",
       "      <td>D1</td>\n",
       "      <td>B5</td>\n",
       "      <td>C5</td>\n",
       "      <td>D5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B6</td>\n",
       "      <td>C6</td>\n",
       "      <td>D6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B7</td>\n",
       "      <td>C7</td>\n",
       "      <td>D7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A    B    C    D   F   G   H\n",
       "0  A0   B0   C0   D0  B4  C4  D4\n",
       "1  A1   B1   C1   D1  B5  C5  D5\n",
       "2  A6  NaN  NaN  NaN  B6  C6  D6\n",
       "3  A7  NaN  NaN  NaN  B7  C7  D7"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leftp.merge(rightp, on = 'A', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d33bc85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+---+---+---+\n",
      "|  A|   B|   C|   D|  F|  G|  H|\n",
      "+---+----+----+----+---+---+---+\n",
      "| A0|  B0|  C0|  D0| B4| C4| D4|\n",
      "| A1|  B1|  C1|  D1| B5| C5| D5|\n",
      "| A6|null|null|null| B6| C6| D6|\n",
      "| A7|null|null|null| B7| C7| D7|\n",
      "+---+----+----+----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lefts.join(rights,on='A',how='right').orderBy('A',ascending=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93425d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  A0  B0  C0  D0\n",
      "1  A1  B1  C1  D1\n",
      "2  A2  B2  C2  D2\n",
      "3  A3  B3  C3  D3\n",
      "+---+----+----+----+----+----+----+\n",
      "|  A|   B|   C|   D|   F|   G|   H|\n",
      "+---+----+----+----+----+----+----+\n",
      "| A0|  B0|  C0|  D0|  B4|  C4|  D4|\n",
      "| A1|  B1|  C1|  D1|  B5|  C5|  D5|\n",
      "| A2|  B2|  C2|  D2|null|null|null|\n",
      "| A3|  B3|  C3|  D3|null|null|null|\n",
      "| A6|null|null|null|  B6|  C6|  D6|\n",
      "| A7|null|null|null|  B7|  C7|  D7|\n",
      "+---+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "leftp.merge(rightp,on='A',how='outer') #\n",
    "print(leftp)\n",
    "lefts.join(rights,on='A',how='full').orderBy('A',ascending=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d409cc",
   "metadata": {},
   "source": [
    "### Concat Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db1d8cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1  col2  col3\n",
      "0    a     2     3\n",
      "1    b     5     6\n",
      "2    c     8     9\n",
      "3    a     2     3\n",
      "4    b     5     6\n",
      "5    c     8     9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[col1: string, col2: bigint, col3: bigint]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [('a', 2, 3),\n",
    "           ('b', 5, 6),\n",
    "           ('c', 8, 9),\n",
    "           ('a', 2, 3),\n",
    "           ('b', 5, 6),\n",
    "           ('c', 8, 9)]\n",
    "col_name = ['col1', 'col2', 'col3']\n",
    "#\n",
    "dp = pd.DataFrame(my_list,columns=col_name)\n",
    "print(dp)\n",
    "ds = spark.createDataFrame(my_list,schema=col_name)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5daa2d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  col1  col2  col3 concat\n",
      "0    a     2     3     a2\n",
      "1    b     5     6     b5\n",
      "2    c     8     9     c8\n",
      "3    a     2     3     a2\n",
      "4    b     5     6     b5\n",
      "5    c     8     9     c8\n",
      "+----+----+----+------+\n",
      "|col1|col2|col3|concat|\n",
      "+----+----+----+------+\n",
      "|   a|   2|   3|    a2|\n",
      "|   b|   5|   6|    b5|\n",
      "|   c|   8|   9|    c8|\n",
      "|   a|   2|   3|    a2|\n",
      "|   b|   5|   6|    b5|\n",
      "|   c|   8|   9|    c8|\n",
      "+----+----+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp['concat'] = dp.apply(lambda x:'%s%s'%(x['col1'],x['col2']),axis=1)\n",
    "#\n",
    "print(dp)\n",
    "ds.withColumn('concat',F.concat('col1','col2')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ee20b",
   "metadata": {},
   "source": [
    "### GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "103b3dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      col2  col3\n",
      "col1            \n",
      "a        2     3\n",
      "b        5     6\n",
      "c        8     9\n",
      "+----+---------+---------+\n",
      "|col1|min(col2)|avg(col3)|\n",
      "+----+---------+---------+\n",
      "|   c|        8|      9.0|\n",
      "|   b|        5|      6.0|\n",
      "|   a|        2|      3.0|\n",
      "+----+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp = dp.groupby(['col1']).agg({'col2':'min','col3':'mean'})\n",
    "print(dp)\n",
    "#\n",
    "ds.groupBy(['col1']).agg({'col2': 'min', 'col3': 'avg'}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2245531",
   "metadata": {},
   "source": [
    "### Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a232b5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col2    2    5    8\n",
      "col1               \n",
      "a     3.0  NaN  NaN\n",
      "b     NaN  6.0  NaN\n",
      "c     NaN  NaN  9.0\n",
      "+----+----+----+----+\n",
      "|col1|   2|   5|   8|\n",
      "+----+----+----+----+\n",
      "|   c|null|null|  18|\n",
      "|   b|null|  12|null|\n",
      "|   a|   6|null|null|\n",
      "+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pd2 = pd.pivot_table(dp, values='col3', index='col1', columns='col2', aggfunc=np.sum)\n",
    "print(pd2)\n",
    "#\n",
    "ds.groupBy(['col1']).pivot('col2').sum('col3').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b44a65",
   "metadata": {},
   "source": [
    "### Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "511ced45",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'A':['a','b','c','d'],'B':['m','m','n','n'],'C':[1,2,3,6]}\n",
    "dp = pd.DataFrame(d)\n",
    "ds = spark.createDataFrame(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93ea6227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>m</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>m</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  a  m  1\n",
       "1  b  m  2\n",
       "2  c  n  3\n",
       "3  d  n  6"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae9a7f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C  rank\n",
      "0  a  m  1   2.0\n",
      "1  b  m  2   1.0\n",
      "2  c  n  3   2.0\n",
      "3  d  n  6   1.0\n",
      "+---+---+---+----+\n",
      "|  A|  B|  C|rank|\n",
      "+---+---+---+----+\n",
      "|  b|  m|  2|   1|\n",
      "|  a|  m|  1|   2|\n",
      "|  d|  n|  6|   1|\n",
      "|  c|  n|  3|   2|\n",
      "+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dp['rank'] = dp.groupby('B')['C'].rank('dense',ascending=False) #\n",
    "print(dp)\n",
    "from pyspark.sql.window import Window\n",
    "w = Window.partitionBy('B').orderBy(ds.C.desc())\n",
    "ds = ds.withColumn('rank',F.rank().over(w)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab1992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf3ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509552cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b74118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca0f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478db447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f59d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6f2ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dabfdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336daa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615989a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89db8713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c863cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6a18d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7036034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07972d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dba062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c4485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521f64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac1c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f549b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050cc499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
